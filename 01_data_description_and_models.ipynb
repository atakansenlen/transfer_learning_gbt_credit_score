{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats \n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\asenlen\\Desktop\\Projects\\tez\\modeller\\lending_club\\accepted_2007_to_2018Q4.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[(data['loan_status']=='Fully Paid')|(data['loan_status']=='Charged Off')].reset_index()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspected_list=['avg_cur_bal','bc_open_to_buy','emp_length','mo_sin_old_rev_tl_op','mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','mths_since_recent_bc','num_accts_ever_120_pd','num_actv_bc_tl','num_actv_rev_tl','num_bc_sats','num_il_tl','num_op_rev_tl','num_rev_accts','num_rev_tl_bal_gt_0','num_sats','num_tl_op_past_12m','pct_tl_nvr_dlq','percent_bc_gt_75','tot_coll_amt','tot_cur_bal','tot_hi_cred_lim','total_bal_ex_mort','total_bc_limit','total_il_high_credit_limit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[suspected_list].to_csv('suspected_list.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[suspected_list].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].loc[data[['mo_sin_old_rev_tl_op','mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','num_accts_ever_120_pd','num_actv_bc_tl','num_actv_rev_tl','num_il_tl']].isnull().sum(axis=1)>3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(data[suspected_list].corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified=['acc_open_past_24mths','bc_util','delinq_2yrs','issue_d','last_credit_pull_d','mort_acc','pub_rec','pub_rec_bankruptcies','recoveries','zip_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[modified].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(data[modified].corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(suspected_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list=['addr_state','annual_inc','application_type','dti','earliest_cr_line','fico_range_high','fico_range_low','funded_amnt','funded_amnt_inv','grade','home_ownership','initial_list_status','inq_last_6mths','installment','int_rate','loan_amnt','loan_status','open_acc','purpose','revol_bal','revol_util','term','title','total_acc','verification_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[modified+variable_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fico_range_high'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_util'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_delete=['acc_open_past_24mths','bc_util','fico_range_low','funded_amnt','funded_amnt_inv','loan_amnt','pub_rec_bankruptcies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(second_delete,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['open_acc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total_acc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['total_acc','fico_range_high'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delinq_2yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delinq_2yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delinq_2yrs'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delinq_2yrs'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delinq_2yrs'].loc[data['delinq_2yrs']>4]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delinq_2yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delinq_2yrs = data.hvplot.hist(\n",
    "    y='delinq_2yrs', by='loan_status', bins=10, width=600, height=350, \n",
    "    title=\"delinq_2yrs Distribution\", xlabel='dti', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"delinq_2_yrs for Charged Off\"\n",
    "\n",
    "delinq_2yrs_charged_off = data[data['loan_status']=='Charged Off'].hvplot.hist(\n",
    "    y='delinq_2yrs', bins=10, width=600, height=350, \n",
    "    title=\"delinq_2yrs Distribution\", xlabel='dti', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"delinq_2_yrs for Fully Paid\"\n",
    "\n",
    "delinq_2yrs_fully_paid = data[data['loan_status']=='Fully Paid'].hvplot.hist(\n",
    "    y='delinq_2yrs', bins=10, width=600, height=350, \n",
    "    title=\"delinq_2yrs Distribution\", xlabel='dti', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "delinq_2yrs + delinq_2yrs_charged_off + delinq_2yrs_fully_paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myhist=sns.FacetGrid(data, col='purpose',col_wrap=4, xlim=(0,6))\n",
    "\n",
    "myhist.map_dataframe(sns.histplot,x='delinq_2yrs',hue='loan_status',alpha=0.4, multiple='stack', bins=30,legend=True, palette='coolwarm',color=10*'label')\n",
    "\n",
    "myhist.set_axis_labels(\"delinq_2_yrs\", \"frequency\")\n",
    "\n",
    "myhist.fig.subplots_adjust(top=0.95)\n",
    "myhist.fig.suptitle('Delinq_2_years for Each Purpose', fontsize=14)\n",
    "plt.legend(labels=['Fully Paid','Charged Off'],loc='lower right')\n",
    "#hist_countries=[]\n",
    "#line_position = [14, 23, 11, 39]\n",
    "\n",
    "#for ax, pos in zip(myhist.axes.flat, line_position):\n",
    "    #ax.axvline(x=pos, color='r', linestyle=':')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='delinq_2yrs', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.xlabel('Date', fontsize=16)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='delinq_2yrs', data=data[data['purpose']==purpose]).tick_params(labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_ratio_by_purpose(columname):\n",
    "    ratio_list=[[] for i in data['purpose'].unique()]\n",
    "    for index, purpose in enumerate(data['purpose'].unique()):\n",
    "        for size in data[columname].loc[data['purpose']==purpose].value_counts():\n",
    "            ratio_list[index].append(size/data[data['purpose']==purpose].shape[0])\n",
    "    return ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ratio_by_purpose('delinq_2yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('issue_d', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_credit_pull_d'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('last_credit_pull_d', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mort Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mort_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mort_acc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mort_acc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#napsak\n",
    "data['mort_acc'].loc[data['mort_acc']>7]=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mort_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_acc = data.hvplot.hist(\n",
    "    y='mort_acc', by='loan_status', bins=10, width=600, height=350, \n",
    "    title=\"mort_acc Distribution\", xlabel='mort_acc', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"mort_acc for Charged Off\"\n",
    "\n",
    "mort_acc_charged_off = data[data['loan_status']=='Charged Off'].hvplot.hist(\n",
    "    y='mort_acc', bins=10, width=600, height=350, \n",
    "    title=\"mort_acc for Charged Off\", xlabel='mort_acc', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"mort_acc for Fully Paid\"\n",
    "\n",
    "mort_acc_fully_paid = data[data['loan_status']=='Fully Paid'].hvplot.hist(\n",
    "    y='mort_acc', bins=10, width=600, height=350, \n",
    "    title=\"mort_acc Distribution\", xlabel='mort_acc', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "mort_acc + mort_acc_charged_off + mort_acc_fully_paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='mort_acc', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='mort_acc', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ratio_by_purpose('mort_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pub_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pub_rec'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pub_rec'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pub_rec'].loc[data['pub_rec']>2]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='pub_rec', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='pub_rec', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ratio_by_purpose('pub_rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recoveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['recoveries'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recoveries will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('recoveries',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "addr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['addr_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['addr_state'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zip_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('zip_code',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['addr_state'].value_counts()[0:25].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['addr_state'].value_counts()[0:25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_states=data['addr_state'].value_counts()[0:25].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['addr_state'].loc[-data['addr_state'].isin(top_states)]='Other'\n",
    "# i will add the level 'other' to the addr_state, if it is not in top 25 states, because number of levels are too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['addr_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Annual_Inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annual_inc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annual_inc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['annual_inc'], bins=10,label='annual_inc',alpha=0.7,)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seems like huge chunk of data is limited to 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['annual_inc']<1000000].shape[0]/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_inc = data[data['annual_inc']<250000].hvplot.hist(\n",
    "    y='annual_inc', by='loan_status', bins=10, width=600, height=350, \n",
    "    title=\"annual_inc Distribution\", xlabel='annual_inc', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"annual_inc for Charged Off\"\n",
    "\n",
    "annual_inc_charged_off = data[(data['annual_inc']<250000)&(data['loan_status']=='Charged Off')].hvplot.hist(\n",
    "    y='annual_inc', bins=10, width=600, height=350, \n",
    "    title=\"annual_inc for Charged Off\", xlabel='annual_inc', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"annual_inc for Fully Paid\"\n",
    "\n",
    "annual_inc_fully_paid = data[(data['annual_inc']<250000)&(data['loan_status']=='Fully Paid')].hvplot.hist(\n",
    "    y='annual_inc', bins=10, width=600, height=350, \n",
    "    title=\"mort_annual_inc Fully Paid\", xlabel='annual_inc', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "annual_inc + annual_inc_charged_off + annual_inc_fully_paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='annual_inc', data=data[(data['purpose']==purpose)&(data['annual_inc']<250000)], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['annual_inc']<300000].shape[0]/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].loc[data['annual_inc']>300000].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['annual_inc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "application type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['application_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['application_type'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='application_type', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='application_type', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ratio_by_purpose('application_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['application_type'].loc[data['purpose']=='home_improvement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='application_type', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_ratio_by_loan_status(columname):\n",
    "    ratio_list=[[] for i in data['loan_status'].unique()]\n",
    "    for index, loan_status in enumerate(data['loan_status'].unique()):\n",
    "        for size in data[columname].loc[data['loan_status']==loan_status].value_counts():\n",
    "            ratio_list[index].append(size/data[data['loan_status']==loan_status].shape[0])\n",
    "    return ratio_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ratio_by_loan_status('application_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems like application type doesn't have much effect on loan status, also the ratio barely changews through different purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['application_type'].unique():\n",
    "    print (data['loan_status'].loc[data['application_type']==i].value_counts()/data['loan_status'].loc[data['application_type']==i].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now it can stay but i will deal with it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dti'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dti'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['dti']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only two entries has negative dti ratios, it seems like they are outliers, i will just remove them\n",
    "data=data[-data['dti']<0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dti'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = data.hvplot.hist(\n",
    "    y='dti', by='loan_status', bins=10, width=600, height=350, \n",
    "    title=\"dti Distribution\", xlabel='dti', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"dti for Charged Off\"\n",
    "\n",
    "dti_charged_off = data.hvplot.hist(\n",
    "    y='dti', bins=10, width=600, height=350, \n",
    "    title=\"dti for Charged Off\", xlabel='dti', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"dti for Fully Paid\"\n",
    "\n",
    "dti_fully_paid = data.hvplot.hist(\n",
    "    y='dti', bins=10, width=600, height=350, \n",
    "    title=\"dti_inc Fully Paid\", xlabel='dti', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "dti + dti_charged_off + dti_fully_paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "plt.hist(data['dti'], bins=15,label='dti',alpha=0.7,)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dti'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dti'].loc[data['dti']<1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dti'].loc[data['dti']>60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "plt.hist(data['dti'].loc[data['dti']>50], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1den kucuk ve 600den buyuk seyler outlier gibi\n",
    "data['dti'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "earliest_cr_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliest_cr_line'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(data['earliest_cr_line']).dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliest_cr_line']=pd.to_datetime(data['earliest_cr_line']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_cr_line = data.hvplot.hist(\n",
    "    y='earliest_cr_line', by='loan_status', bins=10, width=600, height=350, \n",
    "    title=\"earliest_cr_line Distribution\", xlabel='earliest_cr_line', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"earliest_cr_line for Charged Off\"\n",
    "\n",
    "earliest_cr_line_charged_off = data.hvplot.hist(\n",
    "    y='earliest_cr_line', bins=10, width=600, height=350, \n",
    "    title=\"earliest_cr_line for Charged Off\", xlabel='earliest_cr_line', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "title=\"earliest_cr_line for Fully Paid\"\n",
    "\n",
    "earliest_cr_line_fully_paid = data.hvplot.hist(\n",
    "    y='earliest_cr_line', bins=10, width=600, height=350, \n",
    "    title=\"earliest_cr_line Fully Paid\", xlabel='earliest_cr_line', ylabel='Count', \n",
    "    alpha=0.4, legend='top'\n",
    ")\n",
    "\n",
    "earliest_cr_line + earliest_cr_line_charged_off + earliest_cr_line_fully_paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='earliest_cr_line', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=6)\n",
    "    plt.title(f'{purpose}')\n",
    "    plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='earliest_cr_line', data=data[data['purpose']==purpose]).tick_params(labelsize=6)\n",
    "    plt.title(f'{purpose}')\n",
    "    plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "sns.countplot(x='earliest_cr_line', data=data).tick_params(labelsize=10)\n",
    "plt.title('earliest_cr_line Distribution')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliest_cr_line'].loc[data['earliest_cr_line']<1970].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].loc[data['earliest_cr_line']<1970].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will remove the lines earlier than 1970, because they are so outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['earliest_cr_line']>1969].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "sns.countplot(x='earliest_cr_line', data=data).tick_params(labelsize=10)\n",
    "plt.title('earliest_cr_line Distribution')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['earliest_cr_line'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade']=data['grade'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "sns.countplot(x='grade', data=data).tick_params(labelsize=20)\n",
    "plt.title('grade Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='grade', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='grade', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='grade', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade is ordinal categorical variable, so i will convert grade into numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade_factorized'],grade_uniques=pd.factorize(data['grade'], sort=True)\n",
    "data['grade_factorized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='grade_factorized', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('grade',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "home_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['home_ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['home_ownership'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will get rid of the levels any, other, none, since they are very few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ownership_levels=data['home_ownership'].value_counts()[0:3].index\n",
    "data=data[data['home_ownership'].isin(home_ownership_levels)].reset_index(drop=True)\n",
    "data['home_ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='home_ownership', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='home_ownership', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='home_ownership', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial list status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['initial_list_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['initial_list_status'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='initial_list_status', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='initial_list_status', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='initial_list_status', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inq_last_6mths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inq_last_6mths'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inq_last_6mths'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[-data['inq_last_6mths'].isnull()].reset_index(drop=True)\n",
    "data['inq_last_6mths'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will winsorize the values after 5 because the amount is so small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['inq_last_6mths'].loc[data['inq_last_6mths']>5]=5\n",
    "data['inq_last_6mths'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='inq_last_6mths', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='inq_last_6mths', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='inq_last_6mths', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['installment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['installment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['installment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['installment'], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['installment'].loc[data['installment']>1250], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installment_box = data.hvplot.box(\n",
    "    y='installment', subplots=True, width=300, height=350, \n",
    "    title=\"Installment\", xlabel='Loan Installment', ylabel='Value'\n",
    ")\n",
    "installment_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "int_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['int_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['int_rate'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['int_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['int_rate'], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installment_box = data.hvplot.box(\n",
    "    y='int_rate', subplots=True, width=300, height=350, \n",
    "    title=\"int_rate\", xlabel='int_rate', ylabel='Value'\n",
    ")\n",
    "installment_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['int_rate'].loc[data['int_rate']>25], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='loan_status', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['loan_status'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['open_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['open_acc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_acc = data.hvplot.box(\n",
    "    y='open_acc', subplots=True, width=300, height=350, \n",
    "    title=\"open_acc\", xlabel='open_acc', ylabel='Value'\n",
    ")\n",
    "open_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['open_acc'].loc[data['open_acc']>25], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['open_acc'], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['open_acc'].loc[data['open_acc']>40].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revol_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_bal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_bal'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_bal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revol_bal = data.hvplot.box(\n",
    "    y='revol_bal', subplots=True, width=300, height=350, \n",
    "    title=\"revol_bal\", xlabel='revol_bal', ylabel='Value'\n",
    ")\n",
    "revol_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_bal'].loc[data['revol_bal']>1000000].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['revol_bal']<=1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['revol_bal'].loc[data['revol_bal']>200000], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('application_type',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revol_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_util'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_util'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['revol_util'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_util'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revol_util = data.hvplot.box(\n",
    "    y='revol_util', subplots=True, width=300, height=350, \n",
    "    title=\"revol_util\", xlabel='revol_util', ylabel='Value'\n",
    ")\n",
    "revol_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "plt.hist(data['revol_util'].loc[data['revol_util']>100], bins=15,label='dti',alpha=0.7,)\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revol_util'].loc[data['revol_util']>120].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['revol_util']<120]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['term'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='term', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='term', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='term', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['term'].unique():\n",
    "    print (data['loan_status'].loc[data['term']==i].value_counts()/data['loan_status'].loc[data['term']==i].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ratio_by_purpose('term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'].value_counts()# it is directly related with purpose so i will remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verification_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verification_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verification_status'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "#plt.xlabel(matplotlib.pyplot.text(0,0,'mort_acc'), fontsize=16, horizontalalignment='left',multialignment='left')\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='verification_status', data=data[data['purpose']==purpose], hue='loan_status').tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,status in enumerate(data['loan_status'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='verification_status', data=data[data['loan_status']==status]).tick_params(labelsize=8)\n",
    "    plt.title(f'{status}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 60))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for index,purpose in enumerate(data['purpose'].unique()):  \n",
    "    plt.subplot(16, 4, index+1)\n",
    "    sns.countplot(x='verification_status', data=data[data['purpose']==purpose]).tick_params(labelsize=8)\n",
    "    plt.title(f'{purpose}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['verification_status'].unique():#burasi biraz supheli outputu cok etkilemiyor gibi\n",
    "    print (data['loan_status'].loc[data['verification_status']==i].value_counts()/data['loan_status'].loc[data['verification_status']==i].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verification_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grade_factorized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression for y-x realtionship investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns=['addr_state','home_ownership','initial_list_status','term','verification_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied_data=pd.get_dummies(data, columns=dummy_columns, drop_first=True)\n",
    "dummied_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied_data.drop_duplicates(inplace=True)\n",
    "dummied_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers will be removed for linear regression\n",
    "regression_data=dummied_data.copy()\n",
    "regression_data=regression_data[regression_data['annual_inc']<250000]\n",
    "regression_data=regression_data[regression_data['dti']>=1]\n",
    "regression_data=regression_data[regression_data['dti']<=60]\n",
    "regression_data=regression_data[regression_data['installment']<1501]\n",
    "regression_data=regression_data[regression_data['open_acc']<41]\n",
    "regression_data=regression_data[regression_data['revol_bal']<200000]\n",
    "regression_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data.to_csv(r\"C:\\Users\\asenlen\\Desktop\\Projects\\tez\\modeller\\lending_club\\regression_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data=pd.read_csv(r\"C:\\Users\\asenlen\\Desktop\\Projects\\tez\\modeller\\lending_club\\regression_data.csv\")\n",
    "regression_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data.notnull().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data=regression_data[regression_data['mort_acc'].notnull()]\n",
    "regression_data.shape\n",
    "regression_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data[\"purpose\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data['loan_status'],loan_uniques=pd.factorize(regression_data['loan_status'], sort=True)\n",
    "regression_data['loan_status']=1-regression_data['loan_status'].astype(\"int\")\n",
    "regression_data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_consolidation_regression=regression_data[regression_data['purpose']=='debt_consolidation'].reset_index(drop=True)\n",
    "credit_card_regression=regression_data[regression_data['purpose']=='credit_card'].reset_index(drop=True)\n",
    "home_improvement_regression=regression_data[regression_data['purpose']=='home_improvement'].reset_index(drop=True)\n",
    "other_regression=regression_data[regression_data['purpose']=='other'].reset_index(drop=True)\n",
    "major_purchase_regression=regression_data[regression_data['purpose']=='major_purchase'].reset_index(drop=True)\n",
    "small_business_regression=regression_data[regression_data['purpose']=='small_business'].reset_index(drop=True)\n",
    "medical_regression=regression_data[regression_data['purpose']=='medical'].reset_index(drop=True)\n",
    "car_regression=regression_data[regression_data['purpose']=='car'].reset_index(drop=True)\n",
    "moving_regression=regression_data[regression_data['purpose']=='moving'].reset_index(drop=True)\n",
    "vacation_regression=regression_data[regression_data['purpose']=='vacation'].reset_index(drop=True)\n",
    "house_regression=regression_data[regression_data['purpose']=='house'].reset_index(drop=True)\n",
    "wedding=regression_data[regression_data['purpose']=='wedding'].reset_index(drop=True)\n",
    "renewable_energy_regression=regression_data[regression_data['purpose']=='renewable_energy'].reset_index(drop=True)\n",
    "educational_regression=regression_data[regression_data['purpose']=='educational'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_consolidation_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data[\"purpose\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_purchase_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_consolidation_regression_y,debt_consolidation_regression_x=debt_consolidation_regression['loan_status'],debt_consolidation_regression.drop(['purpose','loan_status'],axis=1)\n",
    "credit_card_regression_y,credit_card_regression_x=credit_card_regression['loan_status'],credit_card_regression.drop(['purpose','loan_status'],axis=1)\n",
    "home_improvement_regression_y,home_improvement_regression_x=home_improvement_regression['loan_status'],home_improvement_regression.drop(['purpose','loan_status'],axis=1)\n",
    "other_regression_y,other_regression_x=other_regression['loan_status'],other_regression.drop(['purpose','loan_status'],axis=1)\n",
    "major_purchase_regression_y,major_purchase_regression_x=major_purchase_regression['loan_status'],major_purchase_regression.drop(['purpose','loan_status'],axis=1)\n",
    "small_business_regression_y,small_business_regression_x=small_business_regression['loan_status'],small_business_regression.drop(['purpose','loan_status'],axis=1)\n",
    "medical_regression_y,medical_regression_x=medical_regression['loan_status'],medical_regression.drop(['purpose','loan_status'],axis=1)\n",
    "car_regression_y,car_regression_x=car_regression['loan_status'],car_regression.drop(['purpose','loan_status'],axis=1)\n",
    "moving_regression_y,moving_regression_x=moving_regression['loan_status'],moving_regression.drop(['purpose','loan_status'],axis=1)\n",
    "vacation_regression_y,vacation_regression_x=vacation_regression['loan_status'],vacation_regression.drop(['purpose','loan_status'],axis=1)\n",
    "house_regression_y,house_regression_x=house_regression['loan_status'],house_regression.drop(['purpose','loan_status'],axis=1)\n",
    "wedding_y,wedding_x=wedding['loan_status'],wedding.drop(['purpose','loan_status'],axis=1)\n",
    "renewable_energy_regression_y,renewable_energy_regression_x=renewable_energy_regression['loan_status'],renewable_energy_regression.drop(['purpose','loan_status'],axis=1)\n",
    "educational_regression_y,educational_regression_x=educational_regression['loan_status'],educational_regression.drop(['purpose','loan_status'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"debt_consolidation_regression_y_chargedoff_ratio:{sum(debt_consolidation_regression_y)/len(debt_consolidation_regression_y)}\")\n",
    "print(f\"credit_card_regression_y_chargedoff_ratio:{sum(credit_card_regression_y)/len(credit_card_regression_y)}\")\n",
    "print(f\"home_improvement_regression_y_chargedoff_ratio:{sum(home_improvement_regression_y)/len(home_improvement_regression_y)}\")\n",
    "print(f\"other_regression_y_chargedoff_ratio:{sum(other_regression_y)/len(other_regression_y)}\")\n",
    "print(f\"major_purchase_regression_y_chargedoff_ratio:{sum(major_purchase_regression_y)/len(major_purchase_regression_y)}\")\n",
    "print(f\"small_business_regression_y_chargedoff_ratio:{sum(small_business_regression_y)/len(small_business_regression_y)}\")\n",
    "print(f\"medical_regression_y_chargedoff_ratio:{sum(medical_regression_y)/len(medical_regression_y)}\")\n",
    "print(f\"car_regression_y_chargedoff_ratio:{sum(car_regression_y)/len(car_regression_y)}\")\n",
    "print(f\"moving_regression_y_chargedoff_ratio:{sum(moving_regression_y)/len(moving_regression_y)}\")\n",
    "print(f\"vacation_regression_y_chargedoff_ratio:{sum(vacation_regression_y)/len(vacation_regression_y)}\")\n",
    "print(f\"house_regression_y_chargedoff_ratio:{sum(house_regression_y)/len(house_regression_y)}\")\n",
    "print(f\"wedding_y_chargedoff_ratio:{sum(wedding_y)/len(wedding_y)}\")\n",
    "print(f\"renewable_energy_regression_y_chargedoff_ratio:{sum(renewable_energy_regression_y)/len(renewable_energy_regression_y)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_energy_regression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(debt_consolidation_regression_x)\n",
    "debt_consolidation_regression_x=scaler.transform(debt_consolidation_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(credit_card_regression_x)\n",
    "credit_card_regression_x=scaler.transform(credit_card_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(home_improvement_regression_x)\n",
    "home_improvement_regression_x=scaler.transform(home_improvement_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(other_regression_x)\n",
    "other_regression_x=scaler.transform(other_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(major_purchase_regression_x)\n",
    "major_purchase_regression_x=scaler.transform(major_purchase_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(small_business_regression_x)\n",
    "small_business_regression_x=scaler.transform(small_business_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(medical_regression_x)\n",
    "medical_regression_x=scaler.transform(medical_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(car_regression_x)\n",
    "car_regression_x=scaler.transform(car_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(moving_regression_x)\n",
    "moving_regression_x=scaler.transform(moving_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(vacation_regression_x)\n",
    "vacation_regression_x=scaler.transform(vacation_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(house_regression_x)\n",
    "house_regression_x=scaler.transform(house_regression_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(wedding_x)\n",
    "wedding_x=scaler.transform(wedding_x)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(renewable_energy_regression_x)\n",
    "renewable_energy_regression_x=scaler.transform(renewable_energy_regression_x)\n",
    "#educational category is eliminated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_dict={}\n",
    "\n",
    "reg_model_dict[\"reg_debt_consolidation\"]=LogisticRegression(multi_class='ovr').fit(debt_consolidation_regression_x, debt_consolidation_regression_y)\n",
    "reg_model_dict[\"reg_credit_card\"]=LogisticRegression(multi_class='ovr').fit(credit_card_regression_x, credit_card_regression_y)\n",
    "reg_model_dict[\"reg_home_improvement\"]=LogisticRegression(multi_class='ovr').fit(home_improvement_regression_x, home_improvement_regression_y)\n",
    "reg_model_dict[\"reg_other\"]=LogisticRegression(multi_class='ovr').fit(other_regression_x, other_regression_y)\n",
    "reg_model_dict[\"major_purchase\"]=LogisticRegression(multi_class='ovr').fit(major_purchase_regression_x, major_purchase_regression_y)\n",
    "reg_model_dict[\"reg_small_business\"]=LogisticRegression(multi_class='ovr').fit(small_business_regression_x, small_business_regression_y)\n",
    "reg_model_dict[\"reg_medical\"]=LogisticRegression(multi_class='ovr').fit(medical_regression_x, medical_regression_y)\n",
    "reg_model_dict[\"reg_car\"]=LogisticRegression(multi_class='ovr').fit(car_regression_x, car_regression_y)\n",
    "reg_model_dict[\"reg_moving\"]=LogisticRegression(multi_class='ovr').fit(moving_regression_x, moving_regression_y)\n",
    "reg_model_dict[\"reg_vacation\"]=LogisticRegression(multi_class='ovr').fit(vacation_regression_x, vacation_regression_y)\n",
    "reg_model_dict[\"reg_house\"]=LogisticRegression(multi_class='ovr').fit(house_regression_x, house_regression_y)\n",
    "reg_model_dict[\"reg_wedding\"]=LogisticRegression(multi_class='ovr').fit(wedding_x, wedding_y)\n",
    "reg_model_dict[\"reg_renewable_energy\"]=LogisticRegression(multi_class='ovr').fit(renewable_energy_regression_x, renewable_energy_regression_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open a file and use dump()\n",
    "with open('log_reg_models.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(reg_model_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amick=3\n",
    "def mal():\n",
    "    amick=4\n",
    "    return amick\n",
    "mal()\n",
    "amick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_model_dict[\"reg_debt_consolidation\"].score(debt_consolidation_regression_x,debt_consolidation_regression_y))\n",
    "print(reg_model_dict[\"reg_credit_card\"].score(credit_card_regression_x, credit_card_regression_y))\n",
    "print(reg_model_dict[\"reg_home_improvement\"].score(home_improvement_regression_x, home_improvement_regression_y))\n",
    "print(reg_model_dict[\"reg_other\"].score(other_regression_x, other_regression_y))\n",
    "print(reg_model_dict[\"major_purchase\"].score(major_purchase_regression_x, major_purchase_regression_y))\n",
    "print(reg_model_dict[\"reg_small_business\"].score(small_business_regression_x, small_business_regression_y))\n",
    "print(reg_model_dict[\"reg_medical\"].score(medical_regression_x, medical_regression_y))\n",
    "print(reg_model_dict[\"reg_car\"].score(car_regression_x, car_regression_y))\n",
    "print(reg_model_dict[\"reg_moving\"].score(moving_regression_x, moving_regression_y))\n",
    "print(reg_model_dict[\"reg_vacation\"].score(vacation_regression_x, vacation_regression_y))\n",
    "print(reg_model_dict[\"reg_house\"].score(house_regression_x, house_regression_y))\n",
    "print(reg_model_dict[\"reg_wedding\"].score(wedding_x, wedding_y))\n",
    "print(reg_model_dict[\"reg_renewable_energy\"].score(renewable_energy_regression_x, renewable_energy_regression_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cosine_similarity={}\n",
    "for name,model in reg_model_dict.items():\n",
    "    dict_cosine_similarity[name]=cosine_similarity(model.coef_,reg_model_dict[\"reg_debt_consolidation\"].coef_)\n",
    "\"\"\"cosine_similarity(reg_credit_card.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_home_improvement.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_other.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_small_business.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_medical.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_car.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_moving.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_vacation.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_house.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_wedding.coef_,reg_debt_consolidation.coef_)\n",
    "cosine_similarity(reg_renewable_energy.coef_,reg_debt_consolidation.coef_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('cosine_similarity_scores.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(dict_cosine_similarity, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = gaussian_kde(debt_consolidation_regression_x.transpose(), bw_method='silverman')\n",
    "#evv=kde.pdf(x_grids.transpose())\n",
    "kde.covariance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_2=gaussian_kde(credit_card_regression_x.transpose(), bw_method='silverman')\n",
    "kde_2.covariance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_model_dictionary={}\n",
    "kde_model_dictionary['debt_consolidation_regression_x']=gaussian_kde(debt_consolidation_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['credit_card_regression_x']=gaussian_kde(credit_card_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['home_improvement_regression_x']=gaussian_kde(home_improvement_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['other_regression_x']=gaussian_kde(other_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['major_purchase_regression_x']=gaussian_kde(major_purchase_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['medical_regression_x']=gaussian_kde(medical_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['small_business_regression_x']=gaussian_kde(small_business_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['car_regression_x']=gaussian_kde(car_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['moving_regression_x']=gaussian_kde(moving_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['vacation_regression_x']=gaussian_kde(vacation_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['house_regression_x']=gaussian_kde(house_regression_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['wedding_x']=gaussian_kde(wedding_x.transpose(), bw_method='silverman')\n",
    "kde_model_dictionary['renewable_energy_regression_x']=gaussian_kde(renewable_energy_regression_x.transpose(), bw_method='silverman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_dictionary={}\n",
    "for name,model in kde_model_dictionary.items():\n",
    "    covariance_dictionary[name]=model.covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector_dictionary={}\n",
    "mean_vector_dictionary['debt_consolidation_regression_x']=np.mean(debt_consolidation_regression_x,axis=0)\n",
    "mean_vector_dictionary['credit_card_regression_x']=np.mean(credit_card_regression_x,axis=0)\n",
    "mean_vector_dictionary['home_improvement_regression_x']=np.mean(home_improvement_regression_x,axis=0)\n",
    "mean_vector_dictionary['other_regression_x']=np.mean(other_regression_x,axis=0)\n",
    "mean_vector_dictionary['major_purchase_regression_x']=np.mean(major_purchase_regression_x,axis=0)\n",
    "mean_vector_dictionary['medical_regression_x']=np.mean(medical_regression_x,axis=0)\n",
    "mean_vector_dictionary['small_business_regression_x']=np.mean(small_business_regression_x, axis=0)\n",
    "mean_vector_dictionary['car_regression_x']=np.mean(car_regression_x,axis=0)\n",
    "mean_vector_dictionary['moving_regression_x']=np.mean(moving_regression_x,axis=0)\n",
    "mean_vector_dictionary['vacation_regression_x']=np.mean(vacation_regression_x,axis=0)\n",
    "mean_vector_dictionary['house_regression_x']=np.mean(house_regression_x,axis=0)\n",
    "mean_vector_dictionary['wedding_x']=np.mean(wedding_x,axis=0)\n",
    "mean_vector_dictionary['renewable_energy_regression_x']=np.mean(renewable_energy_regression_x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_mvn(m0, S0, m1, S1):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/44549369/kullback-leibler-divergence-from-gaussian-pm-pv-to-gaussian-qm-qv\n",
    "    The following function computes the KL-Divergence between any two \n",
    "    multivariate normal distributions \n",
    "    (no need for the covariance matrices to be diagonal)\n",
    "    Kullback-Liebler divergence from Gaussian pm,pv to Gaussian qm,qv.\n",
    "    Also computes KL divergence from a single Gaussian pm,pv to a set\n",
    "    of Gaussians qm,qv.\n",
    "    Diagonal covariances are assumed.  Divergence is expressed in nats.\n",
    "    - accepts stacks of means, but only one S0 and S1\n",
    "    From wikipedia\n",
    "    KL( (m0, S0) || (m1, S1))\n",
    "         = .5 * ( tr(S1^{-1} S0) + log |S1|/|S0| + \n",
    "                  (m1 - m0)^T S1^{-1} (m1 - m0) - N )\n",
    "    # 'diagonal' is [1, 2, 3, 4]\n",
    "    tf.diag(diagonal) ==> [[1, 0, 0, 0]\n",
    "                          [0, 2, 0, 0]\n",
    "                          [0, 0, 3, 0]\n",
    "                          [0, 0, 0, 4]]\n",
    "    # See wikipedia on KL divergence special case.              \n",
    "    #KL = 0.5 * tf.reduce_sum(1 + t_log_var - K.square(t_mean) - K.exp(t_log_var), axis=1)   \n",
    "                if METHOD['name'] == 'kl_pen':\n",
    "                self.tflam = tf.placeholder(tf.float32, None, 'lambda')\n",
    "                kl = tf.distributions.kl_divergence(oldpi, pi)\n",
    "                self.kl_mean = tf.reduce_mean(kl)\n",
    "                self.aloss = -(tf.reduce_mean(surr - self.tflam * kl))                               \n",
    "    \"\"\"\n",
    "    # store inv diag covariance of S1 and diff between means\n",
    "    N = m0.shape[0]\n",
    "    iS1 = np.linalg.inv(S1)\n",
    "    diff = m1 - m0\n",
    "\n",
    "    # kl is made of three terms\n",
    "    tr_term   = np.trace(iS1 @ S0)\n",
    "    det_term  = np.log(np.linalg.det(S1)/np.linalg.det(S0)) #np.sum(np.log(S1)) - np.sum(np.log(S0))\n",
    "    quad_term = diff.T @ np.linalg.inv(S1) @ diff #np.sum( (diff*diff) * iS1, axis=1)\n",
    "    #print(tr_term,det_term,quad_term)\n",
    "    return .5 * (tr_term + det_term + quad_term - N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence_dict={}\n",
    "for name,model in covariance_dictionary.items():\n",
    "    kl_divergence_dict[name]=kl_mvn(m0=mean_vector_dictionary['debt_consolidation_regression_x'],S0=covariance_dictionary['debt_consolidation_regression_x'],m1=mean_vector_dictionary[name],S1=covariance_dictionary[name])\n",
    "kl_divergence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('kl_divergence_scores.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(kl_divergence_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_regression\n",
    "wedding\n",
    "debt_consolidation_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_energy_regression_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model denemeleri \n",
    "from sklearn.model_selection import train_test_split\n",
    "debt_consolidation_regression_train, debt_consolidation_regression_test = train_test_split(debt_consolidation_regression, test_size=0.20, random_state=42)\n",
    "credit_card_regression_train, credit_card_regression_test = train_test_split(credit_card_regression, test_size=0.20, random_state=42)\n",
    "home_improvement_regression_train, home_improvement_regression_test = train_test_split(home_improvement_regression, test_size=0.20, random_state=42)\n",
    "other_regression_train, other_regression_test = train_test_split(other_regression, test_size=0.20, random_state=42)\n",
    "major_purchase_regression_train, major_purchase_regression_test = train_test_split(major_purchase_regression, test_size=0.20, random_state=42)\n",
    "small_business_regression_train, small_business_regression_test = train_test_split(small_business_regression, test_size=0.20, random_state=42)\n",
    "medical_regression_train, medical_regression_test = train_test_split(medical_regression, test_size=0.20, random_state=42)\n",
    "car_regression_train, car_regression_test = train_test_split(car_regression, test_size=0.20, random_state=42)\n",
    "moving_regression_train, moving_regression_test = train_test_split(moving_regression, test_size=0.20, random_state=42)\n",
    "vacation_regression_train, vacation_regression_test = train_test_split(vacation_regression, test_size=0.20, random_state=42)\n",
    "house_regression_train, house_regression_test = train_test_split(house_regression, test_size=0.20, random_state=42)\n",
    "wedding_train, wedding_test = train_test_split(wedding, test_size=0.20, random_state=42)\n",
    "renewable_energy_regression_train, renewable_energy_regression_test = train_test_split(renewable_energy_regression, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_consolidation_regression_train_y,debt_consolidation_regression_train_x=debt_consolidation_regression_train['loan_status'],debt_consolidation_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "debt_consolidation_regression_test_y,debt_consolidation_regression_test_x=debt_consolidation_regression_test['loan_status'],debt_consolidation_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "credit_card_regression_train_y,credit_card_regression_train_x=credit_card_regression_train['loan_status'],credit_card_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "credit_card_regression_test_y,credit_card_regression_test_x=credit_card_regression_test['loan_status'],credit_card_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "home_improvement_regression_train_y,home_improvement_regression_train_x=home_improvement_regression_train['loan_status'],home_improvement_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "home_improvement_regression_test_y,home_improvement_regression_test_x=home_improvement_regression_test['loan_status'],home_improvement_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "other_regression_train_y,other_regression_train_x=other_regression_train['loan_status'],other_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "other_regression_test_y,other_regression_test_x=other_regression_test['loan_status'],other_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "major_purchase_regression_train_y,major_purchase_regression_train_x=major_purchase_regression_train['loan_status'],major_purchase_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "major_purchase_regression_test_y,major_purchase_regression_test_x=major_purchase_regression_test['loan_status'],major_purchase_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "small_business_regression_train_y,small_business_regression_train_x=small_business_regression_train['loan_status'],small_business_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "small_business_regression_test_y,small_business_regression_test_x=small_business_regression_test['loan_status'],small_business_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "medical_regression_train_y,medical_regression_train_x=medical_regression_train['loan_status'],medical_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "medical_regression_test_y,medical_regression_test_x=medical_regression_test['loan_status'],medical_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "car_regression_train_y,car_regression_train_x=car_regression_train['loan_status'],car_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "car_regression_test_y,car_regression_test_x=car_regression_test['loan_status'],car_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "moving_regression_train_y,moving_regression_train_x=moving_regression_train['loan_status'],moving_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "moving_regression_test_y,moving_regression_test_x=moving_regression_test['loan_status'],moving_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "vacation_regression_train_y,vacation_regression_train_x=vacation_regression_train['loan_status'],vacation_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "vacation_regression_test_y,vacation_regression_test_x=vacation_regression_test['loan_status'],vacation_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "house_regression_train_y,house_regression_train_x=house_regression_train['loan_status'],house_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "house_regression_test_y,house_regression_test_x=house_regression_test['loan_status'],house_regression_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "wedding_train_y,wedding_train_x=wedding_train['loan_status'],wedding_train.drop(['purpose','loan_status'],axis=1)\n",
    "wedding_test_y,wedding_test_x=wedding_test['loan_status'],wedding_test.drop(['purpose','loan_status'],axis=1)\n",
    "\n",
    "renewable_energy_regression_train_y,renewable_energy_regression_train_x=renewable_energy_regression_train['loan_status'],renewable_energy_regression_train.drop(['purpose','loan_status'],axis=1)\n",
    "renewable_energy_regression_test_y,renewable_energy_regression_test_x=renewable_energy_regression_test['loan_status'],renewable_energy_regression_test.drop(['purpose','loan_status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_consolidation_regression_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model denemeleri\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain=xgb.DMatrix(debt_consolidation_regression_train_x, label=debt_consolidation_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds=10\n",
    "early_stop = xgb.callback.EarlyStopping(rounds=early_stopping_rounds, save_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = xgb.XGBClassifier(max_depth=2, n_estimators=3).fit(X, y)\n",
    "m.get_booster().get_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_debt_consolidation = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=10,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,eval_set=[(debt_consolidation_regression_train_x, debt_consolidation_regression_train_y)],callbacks=[early_stop])\n",
    "gsearch_debt_consolidation.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_debt_consolidation.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('debt_consolidation_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_debt_consolidation, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_debt_consolidation.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,10.5,3).tolist(),\n",
    "\"gamma\":np.linspace(0.2,1,3).tolist(),\n",
    "\"max_depth\":[6,8],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,2).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.07,0.15,3).tolist(),\n",
    "\"n_estimators\":[120]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_debt_consolidation = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,eval_set=[(debt_consolidation_regression_train_x, debt_consolidation_regression_train_y)],callbacks=[early_stop])\n",
    "gsearch_debt_consolidation.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_debt_consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme_dict={'subsample': 1.0,\n",
    " 'n_estimators': 120,\n",
    " 'max_depth': 6,\n",
    " 'gamma': 0.2222222222222222,\n",
    " 'eta': 0.14285714285714285,\n",
    " 'alpha': 0.07999999999999999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_deneme=xgb.XGBClassifier(subsample= 1.0, n_estimators=120,max_depth=6,gamma=0.222,eta=0.1428,alpha=0.0799,objective= \"binary:logistic\")\n",
    "xgb_deneme.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,eval_metric='auc',verbose=20,eval_set=[(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y),(debt_consolidation_regression_test_x,debt_consolidation_regression_test_y)],early_stopping_rounds=50)\n",
    "xgb_deneme.get_booster().dump_model(\"deneme.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_credit_card = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=10,verbose=10)\n",
    "# gsearch_credit_card.fit(credit_card_regression_train_x,credit_card_regression_train_y)\n",
    "gsearch_credit_card.fit(credit_card_regression_train_x,credit_card_regression_train_y)\n",
    "gsearch_credit_card.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_credit_card.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('credit_card_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_credit_card, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,10.5,3).tolist(),\n",
    "\"gamma\":np.linspace(0.2,1,3).tolist(),\n",
    "\"max_depth\":[6,8],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,2).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.07,0.15,3).tolist(),\n",
    "\"n_estimators\":[120]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_credit_card_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "gsearch_credit_card_deep.fit(credit_card_regression_train_x,credit_card_regression_train_y)\n",
    "gsearch_credit_card_deep.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_credit_card_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('credit_card_notl_results:kotu.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_credit_card_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_home_improvement = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=10,verbose=10)\n",
    "# gsearch_home_improvement.fit(home_improvement_regression_train_x,home_improvement_regression_train_y)\n",
    "gsearch_home_improvement.fit(home_improvement_regression_train_x,home_improvement_regression_train_y)\n",
    "gsearch_home_improvement.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_home_improvement.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('home_improvement_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_home_improvement, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_home_improvement.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[0.07142857142857142],\n",
    "\"gamma\":np.linspace(0.7777777777777777,1,3).tolist(),\n",
    "\"max_depth\":[5,6],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "#\"subsample\":np.linspace(0.5,1,2).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.11499999999999998,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_improvement_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "home_improvement_deep.fit(home_improvement_regression_train_x,home_improvement_regression_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(home_improvement_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_improvement_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('home_improvement_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(home_improvement_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_other = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=10,verbose=10)\n",
    "# gsearch_other.fit(other_regression_train_x,other_regression_train_y)\n",
    "gsearch_other.fit(other_regression_train_x,other_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_other.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('other_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_other, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[0.071429],\n",
    "\"gamma\":np.linspace(0.7777777777777777,1,3).tolist(),\n",
    "\"max_depth\":[5,6],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "#\"subsample\":np.linspace(0.5,1,2).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "other_deep.fit(other_regression_train_x,other_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(other_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('other_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(other_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_major_purchase = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=10,verbose=10)\n",
    "# gsearch_major_purchase.fit(major_purchase_regression_train_x,major_purchase_regression_train_y)\n",
    "gsearch_major_purchase.fit(major_purchase_regression_train_x,major_purchase_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_major_purchase.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_major_purchase.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('major_purchase_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_major_purchase, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[0.071429],\n",
    "\"gamma\":np.linspace(0.7777777777777777,1,3).tolist(),\n",
    "\"max_depth\":[5,6],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_major_purchase.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_purchase_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "major_purchase_deep.fit(major_purchase_regression_train_x,major_purchase_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(major_purchase_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('major_purchase_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(major_purchase_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_purchase_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_small_business = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=20,verbose=10)\n",
    "# gsearch_small_business.fit(small_business_regression_train_x,small_business_regression_train_y)\n",
    "gsearch_small_business.fit(small_business_regression_train_x,small_business_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_small_business.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_small_business.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('small_business_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_small_business, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_small_business.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_small_business.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[5,6],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_small_business.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "small_business_deep.fit(small_business_regression_train_x,small_business_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(small_business_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('small_business_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(small_business_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict_1={\n",
    "\"eta\":np.linspace(0,0.5,15).tolist(),\n",
    "\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,15)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[40, 80, 120, 160, 200, 240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_medical = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=20,n_iter=20,verbose=10)\n",
    "# gsearch_medical.fit(medical_regression_train_x,medical_regression_train_y)\n",
    "gsearch_medical.fit(medical_regression_train_x,medical_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_medical.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_medical.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('medical_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_medical, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_medical.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_medical.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[5,6],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_medical.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "medical_deep.fit(medical_regression_train_x,medical_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(medical_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('medical_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(medical_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_car = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=27,n_iter=20,verbose=10)\n",
    "# gsearch_car.fit(car_regression_train_x,car_regression_train_y)\n",
    "gsearch_car.fit(car_regression_train_x,car_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_car.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_car.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('car_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_car, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_car.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_car.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[5,6],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_car.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "car_deep.fit(car_regression_train_x,car_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(car_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('car_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(car_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_moving = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=30,n_iter=20,verbose=10)\n",
    "# gsearch_moving.fit(moving_regression_train_x,moving_regression_train_y)\n",
    "gsearch_moving.fit(moving_regression_train_x,moving_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_moving.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_moving.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('moving_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_moving, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_car.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_car.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[3,5],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_car.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "moving_deep.fit(moving_regression_train_x,moving_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(moving_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('moving_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(moving_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_vacation = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=30,n_iter=20,verbose=10)\n",
    "# gsearch_vacation.fit(vacation_regression_train_x,vacation_regression_train_y)\n",
    "gsearch_vacation.fit(vacation_regression_train_x,vacation_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_vacation.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_vacation.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('vacation_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_vacation, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_vacation.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_vacation.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[3,5],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_vacation.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "vacation_deep.fit(vacation_regression_train_x,vacation_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(vacation_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('vacation_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(vacation_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_house = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=30,n_iter=20,verbose=10)\n",
    "# gsearch_house.fit(house_regression_train_x,house_regression_train_y)\n",
    "gsearch_house.fit(house_regression_train_x,house_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_house.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_house.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('house_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_house, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_house.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_house.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[3,5],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_house.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "house_deep.fit(house_regression_train_x,house_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(house_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('house_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(house_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_wedding = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=30,n_iter=20,verbose=10)\n",
    "# gsearch_wedding.fit(wedding_regression_train_x,wedding_regression_train_y)\n",
    "gsearch_wedding.fit(wedding_train_x,wedding_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_wedding.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_wedding.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[0.03571428571428571],\n",
    "\"gamma\":np.linspace(0.2,1,3).tolist(),\n",
    "\"max_depth\":[6,8],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "#\"subsample\":np.linspace(0.5,1,2).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.07,0.15,3).tolist(),\n",
    "\"n_estimators\":[120,240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('wedding_notl_results1.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_wedding, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_wedding.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_wedding.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[3,5],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_wedding.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[80,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wedding_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "wedding_deep.fit(wedding_train_x,wedding_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(wedding_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('wedding_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(wedding_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wedding_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_renewable_energy = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=60,n_iter=20,verbose=10)\n",
    "# gsearch_renewable_energy.fit(renewable_energy_regression_train_x,renewable_energy_regression_train_y)\n",
    "gsearch_renewable_energy.fit(renewable_energy_regression_train_x,renewable_energy_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(gsearch_renewable_energy.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_renewable_energy.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('renewable_energy_notl_results.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(gsearch_renewable_energy, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict={\n",
    "\"eta\":[gsearch_renewable_energy.best_params_[\"eta\"]],\n",
    "\"gamma\":np.linspace(gsearch_renewable_energy.best_params_[\"gamma\"],1,3).tolist(),\n",
    "\"max_depth\":[5,9],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "\"subsample\":[gsearch_renewable_energy.best_params_[\"subsample\"],1],\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.115,0.15,3).tolist(),\n",
    "\"n_estimators\":[100,240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_energy_deep = GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_grid = parameter_dict, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True,verbose=10)\n",
    "# gsearch_debt_consolidation.fit(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y)\n",
    "renewable_energy_deep.fit(renewable_energy_regression_train_x,renewable_energy_regression_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=pd.DataFrame(renewable_energy_deep.cv_results_)\n",
    "cv_results.sort_values(\"mean_test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_energy_deep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('renewable_energy_notl_results_deep.pkl', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump(renewable_energy_deep, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.xgboost import wandb_callback\n",
    "#wandb.init(project=\"transfer learning\", entity=\"otukenotuk\")\n",
    "\n",
    "#bst = xgb.train(parameter_dict, xgtrain,callbacks=[wandb_callback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in binary mode\n",
    "with open('results/debt_consolidation_notl_results1.pkl', 'rb') as file:\n",
    "      \n",
    "    # Call load method to deserialze\n",
    "    myvar = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar.best_params_\n",
    "myvar.best_params_[\"n_estimators\"]=120\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params={**myvar.best_params_,\"n_estimators\":200,\"max_depth\":7,\"alpha\":0.1,\"gamma\":0.4}\n",
    "new_params,myvar.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.xgboost import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.init(project=\"transfer learning\", entity=\"otukenotuk\",config=new_params)\n",
    "modell=xgb.XGBClassifier(**new_params,eval_metric=[\"auc\",\"logloss\",\"aucpr\"],early_stopping_rounds=20)\n",
    "modell.fit(debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,\n",
    "eval_set=[(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y),\n",
    "(debt_consolidation_regression_test_x,debt_consolidation_regression_test_y)],verbose=True,callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"transfer learning\", entity=\"otukenotuk\",config=new_params,name=\"amcik\")\n",
    "\n",
    "loss = 0.9\n",
    "\n",
    "for i in range(50):\n",
    "    wandb.log({\"train/loss\": loss ** i})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_my_xgb(parameters_path,x_train,y_train,x_test,y_test):\n",
    "    # Open the file in binary mode\n",
    "    with open(parameters_path, 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "        myvar = pickle.load(file)\n",
    "    wandb.init(project=\"transfer learning\", entity=\"otukenotuk\",config=new_params,name=parameters_path)\n",
    "    \n",
    "    model=xgb.XGBClassifier(**myvar.best_params_,eval_metric=[\"auc\",\"logloss\",\"aucpr\"],early_stopping_rounds=20)\n",
    "    model.fit(x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_train,y_train),\n",
    "    (x_test,y_test)],verbose=True,callbacks=[WandbCallback()])\n",
    "    wandb.finish()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_notl=fit_my_xgb(\"results/credit_card_notl_results1.pkl\",credit_card_regression_train_x,credit_card_regression_train_y,credit_card_regression_test_x,credit_card_regression_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file and use dump()\n",
    "with open('no_tl_models/credit_card_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(credit_card_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_notl=fit_my_xgb(\"results/credit_card_notl_results1.pkl\",credit_card_regression_train_x,credit_card_regression_train_y,credit_card_regression_test_x,credit_card_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/credit_card_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(credit_card_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_improvement_notl=fit_my_xgb(\"results/home_improvement_notl_results_deep.pkl\",home_improvement_regression_train_x,home_improvement_regression_train_y,home_improvement_regression_test_x,home_improvement_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/home_improvement_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(home_improvement_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_notl=fit_my_xgb(\"results/other_notl_results_deep.pkl\",other_regression_train_x,other_regression_train_y,other_regression_test_x,other_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/other_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(other_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_purchase_notl=fit_my_xgb(\"results/major_purchase_notl_results_deep.pkl\",major_purchase_regression_train_x,major_purchase_regression_train_y,major_purchase_regression_test_x,major_purchase_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/major_purchase_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(major_purchase_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_notl=fit_my_xgb(\"results/medical_notl_results_deep.pkl\",medical_regression_train_x,medical_regression_train_y,medical_regression_test_x,medical_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/medical_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(medical_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_notl=fit_my_xgb(\"results/small_business_notl_results_deep.pkl\",small_business_regression_train_x,small_business_regression_train_y,small_business_regression_test_x,small_business_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/small_business_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(small_business_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_notl=fit_my_xgb(\"results/car_notl_results_deep.pkl\",car_regression_train_x,car_regression_train_y,car_regression_test_x,car_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/car_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(car_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_notl=fit_my_xgb(\"results/moving_notl_results_deep.pkl\",moving_regression_train_x,moving_regression_train_y,moving_regression_test_x,moving_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/moving_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(moving_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_notl=fit_my_xgb(\"results/vacation_notl_results_deep.pkl\",vacation_regression_train_x,vacation_regression_train_y,vacation_regression_test_x,vacation_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/vacation_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(vacation_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_notl=fit_my_xgb(\"results/house_notl_results_deep.pkl\",house_regression_train_x,house_regression_train_y,house_regression_test_x,house_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/house_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(house_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_energy_notl=fit_my_xgb(\"results/renewable_energy_notl_results_deep.pkl\",renewable_energy_regression_train_x,renewable_energy_regression_train_y,renewable_energy_regression_test_x,renewable_energy_regression_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/renewable_energy_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(renewable_energy_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wedding_notl=fit_my_xgb(\"results/wedding_notl_results_deep.pkl\",wedding_train_x,wedding_train_y,wedding_test_x,wedding_test_y)\n",
    "# Open a file and use dump()\n",
    "with open('no_tl_models/wedding_notl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(wedding_notl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wedding_notl.evals_result().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Models without Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/debt_consolidation_notl_results1.pkl\", 'rb') as file:\n",
    " # Call load method to deserialze\n",
    "     myvar = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvar.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_params={'subsample': 1.0,\n",
    " 'n_estimators': 30,\n",
    " 'max_depth': 6,\n",
    " 'eta': 0.14285714285714285,\n",
    " 'alpha': 0.07999999999999999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,debt_consolidation_regression_test_x,debt_consolidation_regression_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=xgb.XGBClassifier(**source_params,eval_metric=[\"auc\",\"logloss\",\"aucpr\"],early_stopping_rounds=20)\n",
    "base_model.fit(debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,\n",
    "eval_set=[(debt_consolidation_regression_train_x,debt_consolidation_regression_train_y),\n",
    "(debt_consolidation_regression_test_x,debt_consolidation_regression_test_y)],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict_transfer={\n",
    "\"eta\":np.linspace(0,0.2,5).tolist(),\n",
    "#\"gamma\":np.linspace(0,1,10).tolist(),\n",
    "\"max_depth\":[i for i in range(3,7)],\n",
    "#\"min_child_weight\":[i for i in range(1,11)],\n",
    "#\"subsample\":np.linspace(0.5,1,10).tolist(),\n",
    "#\"colsample_bytree\":np.linspace(0.75,1,5).tolist(),\n",
    "#\"colsample_bynode\":np.linspace(0.5,1,7).tolist(),\n",
    "\"alpha\":np.linspace(0.01,0.15,5).tolist(),\n",
    "\"n_estimators\":[30,40, 80, 120, 160, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_my_xgb(parameters_path,x_train,y_train,x_test,y_test):\n",
    "    # Open the file in binary mode\n",
    "    with open(parameters_path, 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "        myvar = pickle.load(file)\n",
    "    wandb.init(project=\"transfer learning\", entity=\"otukenotuk\",config=new_params,name=parameters_path)\n",
    "    \n",
    "    model=xgb.XGBClassifier(**myvar.best_params_,eval_metric=[\"auc\",\"logloss\",\"aucpr\"],early_stopping_rounds=20)\n",
    "    model.fit(x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_train,y_train),\n",
    "    (x_test,y_test)],verbose=True,callbacks=[WandbCallback()])\n",
    "    wandb.finish()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(param_grid,x,y,base_model,name):\n",
    "    my_search= GridSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "    param_grid = param_grid, scoring='roc_auc',n_jobs=-1, cv=None,return_train_score=True)\n",
    "    my_search.fit(x,y,xgb_model =base_model.get_booster())\n",
    "    print(my_search.best_score_)\n",
    "    print(my_search.best_params_)\n",
    "    # Open a file and use dump()\n",
    "    with open(f'results_tl_nonupdate/{name}_tl_model.pkl', 'wb') as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(my_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch_renewable_energy = RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=27), \n",
    "param_distributions = parameter_dict_1, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=60,n_iter=100,verbose=10)\n",
    "# gsearch_renewable_energy.fit(renewable_energy_regression_train_x,renewable_energy_regression_train_y)\n",
    "gsearch_renewable_energy.fit(renewable_energy_regression_train_x,renewable_energy_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(param_grid,x,y,base_model,name,seed=27):\n",
    "    my_search= RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic',seed=seed), \n",
    "    param_distributions = param_grid, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=60,n_iter=100,verbose=10)\n",
    "    my_search.fit(x,y,xgb_model=base_model.get_booster())\n",
    "    print(my_search.best_score_)\n",
    "    print(my_search.best_params_)\n",
    "    # Open a file and use dump()\n",
    "    with open(f'results_tl_nonupdate/{name}_tl_model.pkl', 'wb') as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(my_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,credit_card_regression_train_x,credit_card_regression_train_y,base_model,\"credit_card\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,home_improvement_regression_train_x,home_improvement_regression_train_y,base_model,\"home_improvement\",seed=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,other_regression_train_x,other_regression_train_y,base_model,\"other\",seed=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,major_purchase_regression_train_x,major_purchase_regression_train_y,base_model,\"major_purchase\",seed=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,medical_regression_train_x,medical_regression_train_y,base_model,\"medical\",seed=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,small_business_regression_train_x,small_business_regression_train_y,base_model,\"small_business\",seed=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,car_regression_train_x,car_regression_train_y,base_model,\"car\",seed=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,moving_regression_train_x,moving_regression_train_y,base_model,\"moving\",seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,vacation_regression_train_x,vacation_regression_train_y,base_model,\"vacation\",seed=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,house_regression_train_x,house_regression_train_y,base_model,\"house\",seed=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,renewable_energy_regression_train_x,renewable_energy_regression_train_y,base_model,\"renewable_energy\",seed=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search(parameter_dict_transfer,wedding_train_x,wedding_train_y,base_model,\"wedding\",seed=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_my_xgb_tl_no_update(parameters_path,x_train,y_train,x_test,y_test,base_model,path):\n",
    "    # Open the file in binary mode\n",
    "    with open(parameters_path, 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "        myvar = pickle.load(file)\n",
    "    wandb.init(project=\"transfer learning\", entity=\"otukenotuk\",config=new_params,name=parameters_path)\n",
    "    \n",
    "    model=xgb.XGBClassifier(**myvar.best_params_,eval_metric=[\"auc\",\"logloss\",\"aucpr\"],early_stopping_rounds=20)\n",
    "    model.fit(x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_train,y_train),\n",
    "    (x_test,y_test)],verbose=True,callbacks=[WandbCallback()],xgb_model=base_model.get_booster())\n",
    "    wandb.finish()\n",
    "    with open(path, 'wb') as file:\n",
    "    # A new file will be created\n",
    "        pickle.dump(model, file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_params={'n_estimators': [200], 'max_depth': [3], 'eta': [0.15000000000000002], 'alpha': [0.045]}\n",
    "my_search= RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic'), \n",
    "param_distributions = fake_params, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=60,n_iter=1,verbose=10)\n",
    "my_search.fit(credit_card_regression_train_x,credit_card_regression_train_y,xgb_model=base_model.get_booster())\n",
    "print(my_search.best_score_)\n",
    "print(my_search.best_params_)\n",
    "# Open a file and use dump()\n",
    "with open(f'results_tl_nonupdate/credit_card_tl_model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(my_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/credit_card_tl_model.pkl\",credit_card_regression_train_x,credit_card_regression_train_y,credit_card_regression_test_x,credit_card_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/credit_card_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_improvement_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/home_improvement_tl_model.pkl\",home_improvement_regression_train_x,home_improvement_regression_train_y,home_improvement_regression_test_x,home_improvement_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/home_improvement_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/other_tl_model.pkl\",other_regression_train_x,other_regression_train_y,other_regression_test_x,other_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/other_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_purchase_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/major_purchase_tl_model.pkl\",major_purchase_regression_train_x,major_purchase_regression_train_y,major_purchase_regression_test_x,major_purchase_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/major_purchase_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/medical_tl_model.pkl\",medical_regression_train_x,medical_regression_train_y,medical_regression_test_x,medical_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/medical_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/small_business_tl_model.pkl\",small_business_regression_train_x,small_business_regression_train_y,small_business_regression_test_x,small_business_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/small_business_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/small_business_tl_model.pkl\",small_business_regression_train_x,small_business_regression_train_y,small_business_regression_test_x,small_business_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/small_business_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/car_tl_model.pkl\",car_regression_train_x,car_regression_train_y,car_regression_test_x,car_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/car_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/moving_tl_model.pkl\",moving_regression_train_x,moving_regression_train_y,moving_regression_test_x,moving_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/moving_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/vacation_tl_model.pkl\",vacation_regression_train_x,vacation_regression_train_y,vacation_regression_test_x,vacation_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/vacation_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/house_tl_model.pkl\",house_regression_train_x,house_regression_train_y,house_regression_test_x,house_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/house_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wedding_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/wedding_tl_model.pkl\",wedding_train_x,wedding_train_y,wedding_test_x,wedding_test_y,base_model=base_model,path=\"models_tl_nonupdate/wedding_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renewable_energy_tl_nonupdate=fit_my_xgb_tl_no_update(\"results_tl_nonupdate/renewable_energy_tl_model.pkl\",renewable_energy_regression_train_x,renewable_energy_regression_train_y,renewable_energy_regression_test_x,renewable_energy_regression_test_y,base_model=base_model,path=\"models_tl_nonupdate/renewable_energy_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(parameter_dict_transfer,credit_card_regression_train_x,credit_card_regression_train_y,base_model,\"credit_card\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised TL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_num_boosting_rounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[0].get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[0].get_dump(with_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[0].dump_model(with_stats=True,dump_format='json',fout=\"base_tree1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[0].trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_params={'n_estimators': 1, 'max_depth': 3, 'eta': 0.15000000000000002, 'alpha': 0.045}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme=xgb.XGBClassifier(**fake_params,eval_metric=[\"auc\",\"logloss\",\"aucpr\"])\n",
    "model_deneme.fit(credit_card_regression_train_x,\n",
    "credit_card_regression_train_y,\n",
    "eval_set=[(credit_card_regression_train_x,credit_card_regression_train_y),\n",
    "(credit_card_regression_test_x,credit_card_regression_test_y)],verbose=True,xgb_model=base_model.get_booster())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_num_boosting_rounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.fit(credit_card_regression_train_x,\n",
    "credit_card_regression_train_y,\n",
    "eval_set=[(credit_card_regression_train_x,credit_card_regression_train_y),\n",
    "(credit_card_regression_test_x,credit_card_regression_test_y)],verbose=True,xgb_model=model_deneme.get_booster())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_num_boosting_rounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_booster()[30].trees_to_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_booster()[31].trees_to_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_booster()[32].trees_to_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_booster()[33].trees_to_dataframe().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[12].trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deneme.get_booster()[12].trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdafds=model_deneme.apply(credit_card_regression_train_x,iteration_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdafds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model_deneme.get_booster(),num_trees=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_params2={\"process_type\": \"update\", \"updater\": \"refresh\", \"refresh_leaf\": False,'max_depth': 3, 'eta': 0.15000000000000002, 'alpha': 0.045}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = xgb.DMatrix(credit_card_regression_train_x, credit_card_regression_train_y)\n",
    "refreshed=xgb.train({\"process_type\": \"update\", \"updater\": \"refresh\", \"refresh_leaf\": True,'max_depth': 3, 'eta': 0.15000000000000002, 'alpha': 0.045},\n",
    "dtrain=Xy,num_boost_round=30,xgb_model=base_model.get_booster())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed.num_boosted_rounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed[0].dump_model(with_stats=True,dump_format='json',fout=\"refreshed_tree1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[12].trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed[12].trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed[12].trees_to_dataframe()[refreshed[12].trees_to_dataframe()[\"Gain\"]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = xgb.train(\n",
    "    {\"process_type\": \"update\", \"updater\": \"prune\",\"min_split_loss\":1,\"min_child_weight\":5},\n",
    "    Xy,\n",
    "    num_boost_round=30,\n",
    "    xgb_model=refreshed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_test = xgb.DMatrix(credit_card_regression_test_x, credit_card_regression_test_y)\n",
    "pruned.eval_set(evals=[(Xy_test,\"test_set\")],iteration=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned.eval_set(evals=[(Xy_test,\"test_set\")],iteration=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaka = xgb.train(\n",
    "    {\"process_type\": \"update\", \"updater\": \"prune\",\"min_split_loss\":1,\"min_child_weight\":5},\n",
    "    Xy,\n",
    "    num_boost_round=30,\n",
    "    xgb_model=pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed=xgb.train({\"process_type\": \"update\", \"updater\": \"refresh\", \"refresh_leaf\": True},\n",
    "dtrain=Xy,num_boost_round=30,xgb_model=base_model.get_booster())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed[12].trees_to_dataframe()[refreshed[12].trees_to_dataframe()[\"Gain\"]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned[12].trees_to_dataframe()[pruned[12].trees_to_dataframe()[\"Gain\"]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed[12].trees_to_dataframe().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned[12].trees_to_dataframe().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaka[12].trees_to_dataframe().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned[15].trees_to_dataframe().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaka[15].trees_to_dataframe().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[12].trees_to_dataframe().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.get_booster()[12].trees_to_dataframe()[base_model.get_booster()[12].trees_to_dataframe()[\"Node\"]==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned[12].trees_to_dataframe()[pruned[12].trees_to_dataframe()[\"Node\"]==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned[0].dump_model(with_stats=True,dump_format='json',fout=\"pruned_tree1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_params={'subsample': 1.0,\n",
    " 'n_estimators': 30,\n",
    " 'max_depth': 6,\n",
    " 'eta': 0.14285714285714285,\n",
    " 'alpha': 0.07999999999999999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tl={'subsample': 1.0,\n",
    " 'max_depth': 6,\n",
    " 'eta': 0.14285714285714285,\n",
    " 'alpha': 0.07999999999999999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osuken={\"adfa\":2,\"fada\":3}\n",
    "osuken.pop(\"adfa\")\n",
    "osuken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**osuken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3,\"afsdada\", f\"fada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiround_revising(num_rounds,source_params,x_source,y_source,x_target,y_target,min_split_loss=1,min_child_weight=5):\n",
    "    dtrain_target=xgb.DMatrix(x_target, y_target)\n",
    "    for i in range(num_rounds):\n",
    "        if i==0:\n",
    "            print(i,\"...epoch for creating first source tree\")\n",
    "            source_model=xgb.XGBClassifier(**source_params,n_estimators=1)\n",
    "            source_model.fit(x_source,y_source)\n",
    "            print(f\"tree_shape is:{source_model.get_booster()[i].trees_to_dataframe().shape}\")\n",
    "        else:\n",
    "            print(i, f\"...epoch for creating {i+1}th source tree\")\n",
    "            source_model.fit(x_source,y_source,xgb_model=pruned_trees)\n",
    "            print(f\"tree_shape is:{source_model.get_booster()[i].trees_to_dataframe().shape}\")\n",
    "\n",
    "        refreshed_trees=xgb.train({\"process_type\": \"update\", \"updater\": \"refresh\", \"refresh_leaf\": True},\n",
    "        dtrain=dtrain_target,num_boost_round=i+1,xgb_model=source_model.get_booster())\n",
    "        print(f\"...epoch {i+1}, trees are re-weighted\",f\"tree_shape is:{refreshed_trees[i].trees_to_dataframe().shape}\")\n",
    "        pruned_trees = xgb.train(\n",
    "        {\"process_type\": \"update\", \"updater\": \"prune\",\"min_split_loss\":min_split_loss,\"min_child_weight\":min_child_weight},\n",
    "        dtrain=dtrain_target,\n",
    "        num_boost_round=i+1,\n",
    "        xgb_model=refreshed_trees)\n",
    "        print(f\"...epoch {i+1}, trees are pruned\",f\"tree_shape is:{pruned_trees[i].trees_to_dataframe().shape}\")        \n",
    "    return pruned_trees\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_base_model=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,credit_card_regression_train_x, credit_card_regression_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_base_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_credit_card=multiround_revised_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_revised(param_grid,x,y,source_model,name,seed=27):\n",
    "    my_search= RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic'), \n",
    "    param_distributions = param_grid, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=seed,n_iter=100,verbose=10)\n",
    "    my_search.fit(x,y,xgb_model=source_model)\n",
    "    print(my_search.best_score_)\n",
    "    print(my_search.best_params_)\n",
    "    # Open a file and use dump()\n",
    "    with open(f'results_tl_update/{name}_tl_model.pkl', 'wb') as file:\n",
    "        # A new file will be created\n",
    "        pickle.dump(my_search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_revised_parameters(num_rounds,source_parameters,param_grid,x_source,y_source,x_target,y_target,min_split_loss_list,min_child_weight_list,name,seed=27):\n",
    "    results_dictionary={}\n",
    "    results_dictionary[\"min_split_loss_list\"]=[]\n",
    "    results_dictionary[\"min_child_weight_list\"]=[]\n",
    "    results_dictionary[\"best_score\"]=[]\n",
    "    results_dictionary[\"best_params\"]=[]\n",
    "    for i in min_split_loss_list:\n",
    "        for j in min_child_weight_list:\n",
    "            results_dictionary[\"min_split_loss_list\"].append(i)\n",
    "            results_dictionary[\"min_child_weight_list\"].append(j)\n",
    "    \n",
    "            source=multiround_revising(num_rounds,source_parameters,x_source,y_source,\n",
    "            x_target,y_target,min_split_loss=i,min_child_weight=j)\n",
    "\n",
    "            my_search= RandomizedSearchCV(estimator = xgb.XGBClassifier(objective= 'binary:logistic'), \n",
    "            param_distributions = param_grid, scoring='roc_auc',n_jobs=-1, cv=5,return_train_score=True,random_state=seed,n_iter=100,verbose=10)\n",
    "            my_search.fit(x_target,y_target,xgb_model=source)\n",
    "            results_dictionary[\"best_score\"].append(my_search.best_score_)\n",
    "            results_dictionary[\"best_params\"].append(my_search.best_params_)\n",
    "            if max(results_dictionary[\"best_score\"])==my_search.best_score_:\n",
    "                    with open(f'results_tl_update/{name}_tl_model.pkl', 'wb') as file:\n",
    "                        # A new file will be created\n",
    "                        pickle.dump(my_search, file)\n",
    "    return results_dictionary\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_major_purchase=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=major_purchase_regression_train_x,\n",
    "y_target=major_purchase_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"major_purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_major_purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_medical=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=medical_regression_train_x,\n",
    "y_target=medical_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"medical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_small_business=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=small_business_regression_train_x,\n",
    "y_target=small_business_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"small_business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_small_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_car=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=car_regression_train_x,\n",
    "y_target=car_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_moving=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=moving_regression_train_x,\n",
    "y_target=moving_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"moving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_vacation=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=vacation_regression_train_x,\n",
    "y_target=vacation_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"vacation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_house=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=house_regression_train_x,\n",
    "y_target=house_regression_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary_wedding=tune_revised_parameters(num_rounds=30,source_parameters=source_tl,param_grid=parameter_dict_transfer,\n",
    "x_source=debt_consolidation_regression_train_x,y_source=debt_consolidation_regression_train_y,x_target=wedding_train_x,\n",
    "y_target=wedding_train_y,min_split_loss_list=[0.001,0.1,1],min_child_weight_list=[2,3,5],name=\"wedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_revised(parameter_dict_transfer,credit_card_regression_train_x,credit_card_regression_train_y,multiround_revised_credit_card,\"credit_card\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_home_improvement=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,home_improvement_regression_train_x, home_improvement_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,home_improvement_regression_train_x,home_improvement_regression_train_y,multiround_revised_home_improvement,\"home_improvement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_other=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,other_regression_train_x, other_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,other_regression_train_x,other_regression_train_y,multiround_revised_other,\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_major_purchase=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,major_purchase_regression_train_x, major_purchase_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,major_purchase_regression_train_x,major_purchase_regression_train_y,multiround_revised_major_purchase,\"major_purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_medical=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,medical_regression_train_x, medical_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,medical_regression_train_x,medical_regression_train_y,multiround_revised_medical,\"medical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_small_business=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,small_business_regression_train_x, small_business_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,small_business_regression_train_x,small_business_regression_train_y,multiround_revised_small_business,\"small_business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_car=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,car_regression_train_x, car_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,car_regression_train_x,car_regression_train_y,multiround_revised_car,\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_moving=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,moving_regression_train_x, moving_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,moving_regression_train_x,moving_regression_train_y,multiround_revised_moving,\"moving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_vacation=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,vacation_regression_train_x, vacation_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,vacation_regression_train_x,vacation_regression_train_y,multiround_revised_vacation,\"vacation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_house=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,house_regression_train_x, house_regression_train_y)\n",
    "random_search_revised(parameter_dict_transfer,house_regression_train_x,house_regression_train_y,multiround_revised_house,\"house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_wedding=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,\n",
    "debt_consolidation_regression_train_y,wedding_train_x, wedding_train_y)\n",
    "random_search_revised(parameter_dict_transfer,wedding_train_x,wedding_train_y,multiround_revised_wedding,\"wedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_my_xgb_tl_with_update(parameters_path,x_train,y_train,x_test,y_test,source_model,path,outside_params=None):\n",
    "    # Open the file in binary mode\n",
    "    with open(parameters_path, 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "        myvar = pickle.load(file)\n",
    "    wandb.init(project=\"transfer learning\", entity=\"otukenotuk\",config=myvar.best_params_,name=parameters_path,settings=wandb.Settings(start_method='thread'))\n",
    "    if outside_params is not None:\n",
    "        xgb_params={**myvar.best_params_,**outside_params}\n",
    "    else:\n",
    "        xgb_params=myvar.best_params_\n",
    "    model=xgb.XGBClassifier(**xgb_params,eval_metric=[\"auc\",\"logloss\",\"aucpr\"],early_stopping_rounds=20)\n",
    "    model.fit(x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_train,y_train),\n",
    "    (x_test,y_test)],callbacks=[WandbCallback()],xgb_model=source_model)\n",
    "    wandb.finish()\n",
    "    with open(path, 'wb') as file:\n",
    "    # A new file will be created\n",
    "        pickle.dump(model, file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_credit_card=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,credit_card_regression_train_x, credit_card_regression_train_y)\n",
    "credit_card_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/credit_card_tl_model.pkl\",credit_card_regression_train_x,credit_card_regression_train_y,credit_card_regression_test_x,credit_card_regression_test_y,source_model=multiround_revised_credit_card,path=\"models_tl_update/credit_card_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_home_improvement=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,home_improvement_regression_train_x, home_improvement_regression_train_y)\n",
    "home_improvement_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/home_improvement_tl_model.pkl\",home_improvement_regression_train_x,home_improvement_regression_train_y,home_improvement_regression_test_x,home_improvement_regression_test_y,source_model=multiround_revised_home_improvement,path=\"models_tl_update/home_improvement_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_other=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,other_regression_train_x, other_regression_train_y)\n",
    "other_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/other_tl_model.pkl\",other_regression_train_x,other_regression_train_y,other_regression_test_x,other_regression_test_y,source_model=multiround_revised_other,path=\"models_tl_update/other_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_major_purchase=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,major_purchase_regression_train_x, major_purchase_regression_train_y)\n",
    "major_purchase_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/major_purchase_tl_model.pkl\",major_purchase_regression_train_x,major_purchase_regression_train_y,major_purchase_regression_test_x,major_purchase_regression_test_y,source_model=multiround_revised_major_purchase,path=\"models_tl_update/major_purchase_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_medical=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,medical_regression_train_x, medical_regression_train_y,min_split_loss=results_dictionary_medical[\"min_split_loss_list\"][3],min_child_weight=results_dictionary_medical[\"min_child_weight_list\"][3])\n",
    "medical_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/medical_tl_model.pkl\",medical_regression_train_x,medical_regression_train_y,medical_regression_test_x,medical_regression_test_y,source_model=multiround_revised_medical,path=\"models_tl_update/medical_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_small_business=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,small_business_regression_train_x, small_business_regression_train_y,min_split_loss=results_dictionary_small_business[\"min_split_loss_list\"][3],min_child_weight=results_dictionary_small_business[\"min_child_weight_list\"][3])\n",
    "small_business_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/small_business_tl_model.pkl\",small_business_regression_train_x,small_business_regression_train_y,small_business_regression_test_x,small_business_regression_test_y,source_model=multiround_revised_small_business,path=\"models_tl_update/small_business_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_small_business=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,small_business_regression_train_x, small_business_regression_train_y)\n",
    "small_business_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/small_business_tl_model.pkl\",small_business_regression_train_x,small_business_regression_train_y,small_business_regression_test_x,small_business_regression_test_y,source_model=multiround_revised_small_business,path=\"models_tl_update/small_business_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_car=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,car_regression_train_x, car_regression_train_y)\n",
    "car_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/car_tl_model.pkl\",car_regression_train_x,car_regression_train_y,car_regression_test_x,car_regression_test_y,source_model=multiround_revised_car,path=\"models_tl_update/car_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_car=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,car_regression_train_x, car_regression_train_y,min_split_loss=results_dictionary_car[\"min_split_loss_list\"][3],min_child_weight=results_dictionary_car[\"min_child_weight_list\"][3])\n",
    "car_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/car_tl_model.pkl\",car_regression_train_x,car_regression_train_y,car_regression_test_x,car_regression_test_y,source_model=multiround_revised_car,path=\"models_tl_update/car_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_moving=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,moving_regression_train_x, moving_regression_train_y)\n",
    "moving_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/moving_tl_model.pkl\",moving_regression_train_x,moving_regression_train_y,moving_regression_test_x,moving_regression_test_y,source_model=multiround_revised_moving,path=\"models_tl_update/moving_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_moving=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,moving_regression_train_x, moving_regression_train_y,min_split_loss=1,min_child_weight=5)\n",
    "moving_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/moving_tl_model.pkl\",moving_regression_train_x,moving_regression_train_y,moving_regression_test_x,moving_regression_test_y,source_model=multiround_revised_moving,path=\"models_tl_update/moving_tl_model.pkl\",outside_params={\"n_estimators\":80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_moving=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,moving_regression_train_x, moving_regression_train_y,min_split_loss=1,min_child_weight=5)\n",
    "moving_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/moving_tl_model.pkl\",moving_regression_train_x,moving_regression_train_y,moving_regression_test_x,moving_regression_test_y,source_model=multiround_revised_moving,path=\"models_tl_update/moving_tl_model.pkl\",outside_params={\"n_estimators\":80})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_vacation=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,vacation_regression_train_x, vacation_regression_train_y)\n",
    "vacation_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/vacation_tl_model.pkl\",vacation_regression_train_x,vacation_regression_train_y,vacation_regression_test_x,vacation_regression_test_y,source_model=multiround_revised_vacation,path=\"models_tl_update/vacation_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_house=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,house_regression_train_x, house_regression_train_y)\n",
    "house_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/house_tl_model.pkl\",house_regression_train_x,house_regression_train_y,house_regression_test_x,house_regression_test_y,source_model=multiround_revised_house,path=\"models_tl_update/house_tl_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiround_revised_wedding=multiround_revising(30,source_tl,debt_consolidation_regression_train_x,debt_consolidation_regression_train_y,wedding_train_x, wedding_train_y)\n",
    "wedding_tl_with_update=fit_my_xgb_tl_with_update(\"results_tl_update/wedding_tl_model.pkl\",wedding_train_x,wedding_train_y,wedding_test_x,wedding_test_y,source_model=multiround_revised_wedding,path=\"models_tl_update/wedding_tl_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2573e0d14c1182e6ab532e17c2db583fd4b314e4563ab3ceb8da5d965ab0d85e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('transfer_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
